{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55075ffe-2e3e-4e12-ac67-894eda5fe209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79500f6-5bc1-4844-9f42-e934d206e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import warnings\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from yolov5.models.common import Conv\n",
    "from yolov5.models.yolo import Detect\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import onnxsim\n",
    "import mo.main as model_optimizer\n",
    "import subprocess\n",
    "import blobconverter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519cbab4-b518-4681-b350-9f67700746a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"/home/matija/Downloads/yolov5n.pt\"\n",
    "fn = \"model\"\n",
    "f_onnx = f\"./{fn}.onnx\"\n",
    "f_simplified = f\"./{fn}-simplified.onnx\" \n",
    "dir_ov = \"./output/\"\n",
    "imgsz = 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b162a2a8-1d5a-44c9-b7b9-282399e7106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# based on export.py\n",
    "model = attempt_load(weights)  # load FP32 model\n",
    "nc, names = model.nc, model.names  # number of classes, class names\n",
    "\n",
    "# Checks\n",
    "opset = 12\n",
    "assert nc == len(names), f'Model class count {nc} != len(names) {len(names)}'\n",
    "\n",
    "# Input\n",
    "gs = int(max(model.stride))  # grid size (max stride)\n",
    "\n",
    "# Image size check\n",
    "if isinstance(imgsz, int):\n",
    "    imgsz = [imgsz, imgsz]\n",
    "for sz in imgsz:\n",
    "    if sz % gs != 0:\n",
    "        raise ValueError(f\"Image size is not a multiple of maximum stride {gs}\")\n",
    "\n",
    "if len(imgsz) != 2:\n",
    "    raise ValueError(f\"Image size must be of length 1 or 2.\")\n",
    "        \n",
    "im = torch.zeros(1, 3, *imgsz)#.to(device)  # image size(1,3,320,192) BCHW iDetection\n",
    "\n",
    "# Update model\n",
    "#im, model = im.half(), model.half()  # to FP16\n",
    "model.eval()\n",
    "for k, m in model.named_modules():\n",
    "    if isinstance(m, Conv):  # assign export-friendly activations\n",
    "        if isinstance(m.act, nn.SiLU):\n",
    "            m.act = SiLU()\n",
    "    elif isinstance(m, Detect):\n",
    "        m.inplace = inplace\n",
    "        m.onnx_dynamic = False\n",
    "        if hasattr(m, 'forward_export'):\n",
    "            m.forward = m.forward_export  # assign custom forward (optional)\n",
    "            \n",
    "for _ in range(2):\n",
    "    y = model(im)  # dry runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5ed02eb-20bb-42ae-9015-b7000309d0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ONNX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matija/Luxonis/model-export/yolo/./yolov5/models/yolo.py:57: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.onnx_dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking exported ONNX\n",
      "Simplifying\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating ONNX\")\n",
    "torch.onnx.export(model, im, f_onnx, verbose=False, opset_version=12,\n",
    "                  training=torch.onnx.TrainingMode.EVAL,\n",
    "                  do_constant_folding=True,\n",
    "                  input_names=['images'],\n",
    "                  output_names=['output'],\n",
    "                  dynamic_axes=None)\n",
    "\n",
    "print(f\"Checking exported ONNX\")\n",
    "# Checks\n",
    "model_onnx = onnx.load(f_onnx)  # load onnx model\n",
    "onnx.checker.check_model(model_onnx)  # check onnx model\n",
    "# LOGGER.info(onnx.helper.printable_graph(model_onnx.graph))  # print\n",
    "\n",
    "print(f\"Simplifying\")\n",
    "onnx_model, check = onnxsim.simplify(model_onnx)\n",
    "assert check, 'assert check failed'\n",
    "#onnx.save(model_onnx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "816e0716-dd10-451d-bd35-206f3b35ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_indices = []\n",
    "for i, n in enumerate(onnx_model.graph.node):\n",
    "    if \"Conv\" in n.name:\n",
    "        conv_indices.append(i)\n",
    "\n",
    "input1, input2, input3 = conv_indices[-3:]\n",
    "\n",
    "sigmoid1 = onnx.helper.make_node(\n",
    "    'Sigmoid',\n",
    "    inputs=[onnx_model.graph.node[input1].output[0]],\n",
    "    outputs=['output1_yolov5'],\n",
    ")\n",
    "\n",
    "sigmoid2 = onnx.helper.make_node(\n",
    "    'Sigmoid',\n",
    "    inputs=[onnx_model.graph.node[input2].output[0]],\n",
    "    outputs=['output2_yolov5'],\n",
    ")\n",
    "\n",
    "sigmoid3 = onnx.helper.make_node(\n",
    "    'Sigmoid',\n",
    "    inputs=[onnx_model.graph.node[input3].output[0]],\n",
    "    outputs=['output3_yolov5'],\n",
    ")\n",
    "\n",
    "onnx_model.graph.node.append(sigmoid1)\n",
    "onnx_model.graph.node.append(sigmoid2)\n",
    "onnx_model.graph.node.append(sigmoid3)\n",
    "\n",
    "onnx.save(onnx_model, f_simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40f306-c99d-433d-a11f-a096279ddb08",
   "metadata": {},
   "source": [
    "# DELETEFROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "87e41ae5-8e7a-46bf-89cb-30266444a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_indices = []\n",
    "for i, n in enumerate(onnx_model.graph.node):\n",
    "    if \"Transpose\" in n.name:\n",
    "        transpose_indices.append(i)\n",
    "\n",
    "input1, input2, input3 = transpose_indices[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5254373a-f897-4978-9eb9-1ddeeff5f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = onnx.helper.make_node('Reshape', name=\"Reshape_r1\", inputs=[onnx_model.graph.node[input1].output[0], \"922\"], outputs=['r1'])\n",
    "r2 = onnx.helper.make_node('Reshape', name=\"Reshape_r2\", inputs=[onnx_model.graph.node[input2].output[0], \"922\"], outputs=['r2'])\n",
    "r3 = onnx.helper.make_node('Reshape', name=\"Reshape_r3\", inputs=[onnx_model.graph.node[input3].output[0], \"922\"], outputs=['r3'])\n",
    "onnx_model.graph.node.append(r1)\n",
    "onnx_model.graph.node.append(r2)\n",
    "onnx_model.graph.node.append(r3)\n",
    "onnx.save(onnx_model, \"test.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed07d9e5-4e5b-498e-a374-657e8ebd2b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 / 159\n",
      "dims: 3\n",
      "data_type: 7\n",
      "name: \"922\"\n",
      "raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\\377\\377\\377\\377\\377\\377\\377\\377U\\000\\000\\000\\000\\000\\000\\000\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, init in enumerate(onnx_model.graph.initializer):\n",
    "    if init.name==\"922\" or init.dims == 3:\n",
    "        print(f\"{i} / {len(onnx_model.graph.initializer)}\")\n",
    "        print(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f42a5fd7-1a4e-4a07-a334-ddf7e3a01485",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = onnx.helper.make_node('Concat', name=\"Concat_new\", inputs=['r1', 'r2', 'r3'], outputs=['yolo_concat'], axis=1)\n",
    "onnx_model.graph.node.append(conc)\n",
    "onnx.save(onnx_model, \"test1.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c71589dd-809f-4dcd-a532-2362e2d23456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_0\n",
      "Sigmoid_1\n",
      "Mul_2\n",
      "Conv_3\n",
      "Sigmoid_4\n",
      "Mul_5\n",
      "Conv_6\n",
      "Sigmoid_7\n",
      "Mul_8\n",
      "Conv_9\n",
      "Sigmoid_10\n",
      "Mul_11\n",
      "Conv_12\n",
      "Sigmoid_13\n",
      "Mul_14\n",
      "Add_15\n",
      "Conv_16\n",
      "Sigmoid_17\n",
      "Mul_18\n",
      "Concat_19\n",
      "Conv_20\n",
      "Sigmoid_21\n",
      "Mul_22\n",
      "Conv_23\n",
      "Sigmoid_24\n",
      "Mul_25\n",
      "Conv_26\n",
      "Sigmoid_27\n",
      "Mul_28\n",
      "Conv_29\n",
      "Sigmoid_30\n",
      "Mul_31\n",
      "Conv_32\n",
      "Sigmoid_33\n",
      "Mul_34\n",
      "Add_35\n",
      "Conv_36\n",
      "Sigmoid_37\n",
      "Mul_38\n",
      "Conv_39\n",
      "Sigmoid_40\n",
      "Mul_41\n",
      "Add_42\n",
      "Conv_43\n",
      "Sigmoid_44\n",
      "Mul_45\n",
      "Concat_46\n",
      "Conv_47\n",
      "Sigmoid_48\n",
      "Mul_49\n",
      "Conv_50\n",
      "Sigmoid_51\n",
      "Mul_52\n",
      "Conv_53\n",
      "Sigmoid_54\n",
      "Mul_55\n",
      "Conv_56\n",
      "Sigmoid_57\n",
      "Mul_58\n",
      "Conv_59\n",
      "Sigmoid_60\n",
      "Mul_61\n",
      "Add_62\n",
      "Conv_63\n",
      "Sigmoid_64\n",
      "Mul_65\n",
      "Conv_66\n",
      "Sigmoid_67\n",
      "Mul_68\n",
      "Add_69\n",
      "Conv_70\n",
      "Sigmoid_71\n",
      "Mul_72\n",
      "Conv_73\n",
      "Sigmoid_74\n",
      "Mul_75\n",
      "Add_76\n",
      "Conv_77\n",
      "Sigmoid_78\n",
      "Mul_79\n",
      "Concat_80\n",
      "Conv_81\n",
      "Sigmoid_82\n",
      "Mul_83\n",
      "Conv_84\n",
      "Sigmoid_85\n",
      "Mul_86\n",
      "Conv_87\n",
      "Sigmoid_88\n",
      "Mul_89\n",
      "Conv_90\n",
      "Sigmoid_91\n",
      "Mul_92\n",
      "Conv_93\n",
      "Sigmoid_94\n",
      "Mul_95\n",
      "Add_96\n",
      "Conv_97\n",
      "Sigmoid_98\n",
      "Mul_99\n",
      "Concat_100\n",
      "Conv_101\n",
      "Sigmoid_102\n",
      "Mul_103\n",
      "Conv_104\n",
      "Sigmoid_105\n",
      "Mul_106\n",
      "MaxPool_107\n",
      "MaxPool_108\n",
      "MaxPool_109\n",
      "Concat_110\n",
      "Conv_111\n",
      "Sigmoid_112\n",
      "Mul_113\n",
      "Conv_114\n",
      "Sigmoid_115\n",
      "Mul_116\n",
      "Resize_118\n",
      "Concat_119\n",
      "Conv_120\n",
      "Sigmoid_121\n",
      "Mul_122\n",
      "Conv_123\n",
      "Sigmoid_124\n",
      "Mul_125\n",
      "Conv_126\n",
      "Sigmoid_127\n",
      "Mul_128\n",
      "Conv_129\n",
      "Sigmoid_130\n",
      "Mul_131\n",
      "Concat_132\n",
      "Conv_133\n",
      "Sigmoid_134\n",
      "Mul_135\n",
      "Conv_136\n",
      "Sigmoid_137\n",
      "Mul_138\n",
      "Resize_140\n",
      "Concat_141\n",
      "Conv_142\n",
      "Sigmoid_143\n",
      "Mul_144\n",
      "Conv_145\n",
      "Sigmoid_146\n",
      "Mul_147\n",
      "Conv_148\n",
      "Sigmoid_149\n",
      "Mul_150\n",
      "Conv_151\n",
      "Sigmoid_152\n",
      "Mul_153\n",
      "Concat_154\n",
      "Conv_155\n",
      "Sigmoid_156\n",
      "Mul_157\n",
      "Conv_158\n",
      "Sigmoid_159\n",
      "Mul_160\n",
      "Concat_161\n",
      "Conv_162\n",
      "Sigmoid_163\n",
      "Mul_164\n",
      "Conv_165\n",
      "Sigmoid_166\n",
      "Mul_167\n",
      "Conv_168\n",
      "Sigmoid_169\n",
      "Mul_170\n",
      "Conv_171\n",
      "Sigmoid_172\n",
      "Mul_173\n",
      "Concat_174\n",
      "Conv_175\n",
      "Sigmoid_176\n",
      "Mul_177\n",
      "Conv_178\n",
      "Sigmoid_179\n",
      "Mul_180\n",
      "Concat_181\n",
      "Conv_182\n",
      "Sigmoid_183\n",
      "Mul_184\n",
      "Conv_185\n",
      "Sigmoid_186\n",
      "Mul_187\n",
      "Conv_188\n",
      "Sigmoid_189\n",
      "Mul_190\n",
      "Conv_191\n",
      "Sigmoid_192\n",
      "Mul_193\n",
      "Concat_194\n",
      "Conv_195\n",
      "Sigmoid_196\n",
      "Mul_197\n",
      "Conv_198\n",
      "Reshape_199\n",
      "Transpose_200\n",
      "Sigmoid_201\n",
      "Slice_206\n",
      "Mul_208\n",
      "Sub_210\n",
      "Add_212\n",
      "Mul_214\n",
      "Expand_221\n",
      "Reshape_269\n",
      "ScatterND_270\n",
      "Slice_275\n",
      "Mul_277\n",
      "Pow_279\n",
      "Mul_281\n",
      "Expand_288\n",
      "Reshape_336\n",
      "ScatterND_337\n",
      "Reshape_338\n",
      "Conv_339\n",
      "Reshape_340\n",
      "Transpose_341\n",
      "Sigmoid_342\n",
      "Slice_347\n",
      "Mul_349\n",
      "Sub_351\n",
      "Add_353\n",
      "Mul_355\n",
      "Expand_362\n",
      "Reshape_410\n",
      "ScatterND_411\n",
      "Slice_416\n",
      "Mul_418\n",
      "Pow_420\n",
      "Mul_422\n",
      "Expand_429\n",
      "Reshape_477\n",
      "ScatterND_478\n",
      "Reshape_479\n",
      "Conv_480\n",
      "Reshape_481\n",
      "Transpose_482\n",
      "Sigmoid_483\n",
      "Slice_488\n",
      "Mul_490\n",
      "Sub_492\n",
      "Add_494\n",
      "Mul_496\n",
      "Expand_503\n",
      "Reshape_551\n",
      "ScatterND_552\n",
      "Slice_557\n",
      "Mul_559\n",
      "Pow_561\n",
      "Mul_563\n",
      "Expand_570\n",
      "Reshape_618\n",
      "ScatterND_619\n",
      "Reshape_620\n",
      "Concat_621\n",
      "\n",
      "\n",
      "\n",
      "Reshape_r1\n",
      "Reshape_r2\n",
      "Reshape_r3\n",
      "Concat_new\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "input: \"715\"\n",
       "input: \"922\"\n",
       "output: \"r3\"\n",
       "name: \"Reshape_r3\"\n",
       "op_type: \"Reshape\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_indices = []\n",
    "for i, n in enumerate(onnx_model.graph.node):\n",
    "    #print(n.name)\n",
    "    print(n.name)\n",
    "    if \"Reshape\" in n.name:\n",
    "        reshape_indices.append(i)\n",
    "reshape_indices\n",
    "onnx_model.graph.node[reshape_indices[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "637164cc-ac1d-4aa0-8325-2a17a68af5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input: \"714\"\n",
       "output: \"715\"\n",
       "name: \"Transpose_482\"\n",
       "op_type: \"Transpose\"\n",
       "attribute {\n",
       "  name: \"perm\"\n",
       "  ints: 0\n",
       "  ints: 1\n",
       "  ints: 3\n",
       "  ints: 4\n",
       "  ints: 2\n",
       "  type: INTS\n",
       "}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model.graph.node[input3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43502b1-4b6c-4786-9cc7-54f71afa5343",
   "metadata": {},
   "source": [
    "# DELETETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6fe67d5-87c4-4b54-b3cb-9e6f3b5eddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onnx = onnx.load(f_simplified)  # load onnx model\n",
    "onnx.checker.check_model(model_onnx)  # check onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d3607d0-d204-43ac-ba70-32d8923c6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace this da pogleda≈° v export.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3bb980-0159-405e-b369-6e608fbaa2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting export with openvino 2021.4.2-3976-0943ed67223-refs/pull/539/head...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mo --input_model ./model-simplified.onnx --output_dir ./output/ --model_name model --data_type FP16 --reverse_input_channel --scale 255 --output \"output1_yolov5,output2_yolov5,output3_yolov5\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino.inference_engine as ie\n",
    "\n",
    "print(f'Starting export with openvino {ie.__version__}...')\n",
    "\n",
    "cmd = f\"mo --input_model {f_simplified} \" \\\n",
    "f\"--output_dir {dir_ov} \" \\\n",
    "f\"--model_name {fn} \" \\\n",
    "'--data_type FP16 ' \\\n",
    "'--reverse_input_channel ' \\\n",
    "'--scale 255 ' \\\n",
    "'--output \"output1_yolov5,output2_yolov5,output3_yolov5\"'\n",
    "\n",
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f03cafb-6a72-4803-b173-41613e9f13c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  Const node 'Resize_118/Add_input_port_1/value214810275' returns shape values of 'float64' type but it must be integer or float32. During Elementwise type inference will attempt to cast to float32\n",
      "[ WARNING ]  Const node 'Resize_140/Add_input_port_1/value218210278' returns shape values of 'float64' type but it must be integer or float32. During Elementwise type inference will attempt to cast to float32\n",
      "[ WARNING ]  Changing Const node 'Resize_118/Add_input_port_1/value214810512' data type from float16 to <class 'numpy.float32'> for Elementwise operation\n",
      "[ WARNING ]  Changing Const node 'Resize_140/Add_input_port_1/value218210473' data type from float16 to <class 'numpy.float32'> for Elementwise operation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b\"Model Optimizer arguments:\\nCommon parameters:\\n\\t- Path to the Input Model: \\t/home/matija/Luxonis/model-export/yolo/./model-simplified.onnx\\n\\t- Path for generated IR: \\t/home/matija/Luxonis/model-export/yolo/./output/\\n\\t- IR output name: \\tmodel\\n\\t- Log level: \\tERROR\\n\\t- Batch: \\tNot specified, inherited from the model\\n\\t- Input layers: \\tNot specified, inherited from the model\\n\\t- Output layers: \\toutput1_yolov5,output2_yolov5,output3_yolov5\\n\\t- Input shapes: \\tNot specified, inherited from the model\\n\\t- Mean values: \\tNot specified\\n\\t- Scale values: \\tNot specified\\n\\t- Scale factor: \\t255.0\\n\\t- Precision of IR: \\tFP16\\n\\t- Enable fusing: \\tTrue\\n\\t- Enable grouped convolutions fusing: \\tTrue\\n\\t- Move mean values to preprocess section: \\tNone\\n\\t- Reverse input channels: \\tTrue\\nONNX specific parameters:\\n\\t- Inference Engine found in: \\t/home/matija/Luxonis/envs/base/lib/python3.8/site-packages/openvino\\nInference Engine version: \\t2021.4.2-3976-0943ed67223-refs/pull/539/head\\nModel Optimizer version: \\t2021.4.2-3976-0943ed67223-refs/pull/539/head\\n[ SUCCESS ] Generated IR version 10 model.\\n[ SUCCESS ] XML file: /home/matija/Luxonis/model-export/yolo/output/model.xml\\n[ SUCCESS ] BIN file: /home/matija/Luxonis/model-export/yolo/output/model.bin\\n[ SUCCESS ] Total execution time: 7.21 seconds. \\n[ SUCCESS ] Memory consumed: 164 MB. \\nIt's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.check_output(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01da3680-26ae-414c-8506-e4d05ecc9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model_openvino_2021.4_6shave.blob...\n",
      "[===========================================       ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binfile = f\"./output/{fn}.bin\"\n",
    "xmlfile = f\"./output/{fn}.xml\"\n",
    "\n",
    "blob_path = blobconverter.from_openvino(\n",
    "    xml=xmlfile,\n",
    "    bin=binfile,\n",
    "    data_type=\"FP16\",\n",
    "    shaves=6,\n",
    "    version=\"2021.4\",\n",
    "    use_cache=False,\n",
    "    output_dir=\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef657288-e750-4bba-a3ef-d07550ec5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18c31f73-2540-43bf-9003-c7f90f68dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors, sides = [], []\n",
    "\n",
    "m = model.module.model[-1] if hasattr(model, 'module') else model.model[-1]\n",
    "for i in range(3):\n",
    "    sides.append(m.anchor_grid[i].size()[2])\n",
    "    for j in range(3):\n",
    "        anchors.extend(m.anchor_grid[i][0, j, 0, 0].numpy())\n",
    "        #print(np.round(m.anchor_grid[i][0, j, 0, 0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b85a2e96-5240-4da0-868a-8e87e24d28a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76.5,\n",
       " 6.4257812,\n",
       " 23.3125,\n",
       " 25.875,\n",
       " 65.8125,\n",
       " 20.921875,\n",
       " 155.75,\n",
       " 10.5546875,\n",
       " 31.6875,\n",
       " 52.625,\n",
       " 295.5,\n",
       " 8.71875,\n",
       " 58.0625,\n",
       " 50.65625,\n",
       " 343.0,\n",
       " 19.953125,\n",
       " 168.625,\n",
       " 60.15625]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "880df00a-7624-405d-aa36-2619b8ca84fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 26, 13]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sides.sort()\n",
    "sides[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "354304a1-99c0-48a1-be46-93972b077968",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"json/yolov5.json\")\n",
    "content = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a592ba2a-dbf6-49ac-92ab-cda6245fbe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'side52': [0, 1, 2], 'side26': [3, 4, 5], 'side13': [6, 7, 8]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = dict()\n",
    "for i, num in enumerate(sides[::-1]):\n",
    "    masks[f\"side{num}\"] = list(range(i*3, i*3+3))\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6d45f63-2349-4119-b9b6-40cba3cfeea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "content[\"nn_config\"][\"input_size\"] = \"x\".join([str(x) for x in imgsz])\n",
    "content[\"nn_config\"][\"NN_specific_metadata\"][\"classes\"] = model.nc\n",
    "content[\"nn_config\"][\"NN_specific_metadata\"][\"anchors\"] = anchors\n",
    "content[\"nn_config\"][\"NN_specific_metadata\"][\"anchor_masks\"] = masks\n",
    "content[\"mappings\"][\"labels\"] = model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18270c1-fe96-4808-a148-8b7fabc7fdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fe6cf4e-ba5e-4fa9-affa-7b4a408f42ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_config': {'output_format': 'detection',\n",
       "  'NN_family': 'YOLO',\n",
       "  'input_size': '416x416',\n",
       "  'NN_specific_metadata': {'classes': 4,\n",
       "   'coordinates': 4,\n",
       "   'anchors': [76.5,\n",
       "    6.4257812,\n",
       "    23.3125,\n",
       "    25.875,\n",
       "    65.8125,\n",
       "    20.921875,\n",
       "    155.75,\n",
       "    10.5546875,\n",
       "    31.6875,\n",
       "    52.625,\n",
       "    295.5,\n",
       "    8.71875,\n",
       "    58.0625,\n",
       "    50.65625,\n",
       "    343.0,\n",
       "    19.953125,\n",
       "    168.625,\n",
       "    60.15625],\n",
       "   'anchor_masks': {'side52': [0, 1, 2],\n",
       "    'side26': [3, 4, 5],\n",
       "    'side13': [6, 7, 8]},\n",
       "   'iou_threshold': 0.5,\n",
       "   'confidence_threshold': 0.5}},\n",
       " 'mappings': {'labels': ['D00', 'D01', 'D02', 'D03']}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1aaaa6-6c31-4018-8984-979fa6f24b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
